{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd13de7-4bd9-4cda-b157-27e56b31e683",
   "metadata": {},
   "source": [
    "# Evolution of COVID in the City of Toronto: Applying ML and NLP models to Classify Infection Classification and Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acca2660-2422-4b90-b8a6-ecc95a7b1e75",
   "metadata": {},
   "source": [
    "## Background and Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952d631-deb6-48a1-bed4-2497706f485c",
   "metadata": {},
   "source": [
    "COVID has struck the whole world and more than two years since the onset of the pandemic, its effects are still felt, irrespective of community or region. Canada has been no exception. However, efforts have been put by governments and civil socieity to contain the spread of the virus. Mass vaccination and booster roll-outs have decreased the lethality of the virus. \n",
    "\n",
    "In this project, I am going to use the data put forth by the [City of Toronto](https://open.toronto.ca/dataset/covid-19-cases-in-toronto/) on COVID cases to produce two types of classifications tasks. In the first one, I will try to use relevant features to discern between the possible outcomes (fatal, resolved, or active) as well as the whether the cases are outbreak-related or not.\n",
    "\n",
    "For the second classification task, I will use information regarding source of infection, neighborhood names nad FSA [Forward Sortation Area](https://www.ic.gc.ca/eic/site/bsf-osb.nsf/eng/br03396.html) to classify whether a case is classified as probable or confirmed. Given the textual, string-based nature of the two aforementioned dimensions, I will use a Multinomial Naive-Bayes text categorizer. This might help in mapping out what areas and postal codes have experienced what type of infection episodes.\n",
    "\n",
    "With that in mind, let's get a look at how the Toronto Public Health services defines the dimensiones of the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10869b70-b31c-4fe0-b5b1-a17cb3b0ebff",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Column Description\n",
    "* **_id**\n",
    "\n",
    "Unique row identifier for Open Data database.\n",
    "\n",
    "* **Assigned_ID**\n",
    "\n",
    "A unique ID assigned to cases by Toronto Public Health for the purposes of posting to Open Data, to allow for tracking of specific cases. Please note, cases may be reclassified or removed from posted datasets over time. This can occur due to duplicate resolution, or other ongoing data cleaning initiatives. In such instances, the Assigned ID of that case will no longer appear on the list and will not get assigned to another case.\n",
    "\n",
    "* **Outbreak Associated**\n",
    "\n",
    "Outbreak associated cases are associated with outbreaks of COVID-19 in Toronto healthcare institutions and healthcare settings (e.g. long-term care homes, retirement homes, hospitals, etc.) and other Toronto congregate settings (such as homeless shelters).\n",
    "\n",
    "* **Age Group**\n",
    "\n",
    "Age at time of illness. Age groups (in years): â‰¤19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90+, unknown (blank)\n",
    "\n",
    "* **Neighbourhood Name**\n",
    "\n",
    "Toronto is divided into 140 geographically distinct neighborhoods that were established to help government and community agencies with local planning by providing socio-economic data for a meaningful geographic area. Please note that client postal code information is mapped to the most up-to-date census tract (CT) and neighbourhood information available from the city. As a result, neighbourhood information is not available for those with missing postal code or when postal code could not be mapped/linked to a CT.\n",
    "\n",
    "* **FSA**\n",
    "\n",
    "Forward sortation area (i.e. first three characters of postal code) based on the case's primary home address. FSA values are generated from client postal codes. One FSA can span multiple neighbourhoods.\n",
    "\n",
    "* **Source of Infection**\n",
    "\n",
    "The most likely way that cases acquired their COVID-19 infection is determined by examining several data fields including:\n",
    "\n",
    "A public health investigator's assessment of the most likely source of infection.Being associated with a confirmed COVID-19 outbreak\n",
    "Reported risk factors such as contact with a known case or travelIf the public health investigator's assessment is absent, then the other data fields are used to infer source of acquisition using the following hierarchy:\n",
    "\n",
    "Cases with episode dates before April 1 2020:\n",
    "\n",
    "-Travel > Outbreak (settings described below) > Household Contact > Close Contact > Community > No information\n",
    "Cases with episode dates on or after April 1 2020:\n",
    "\n",
    "-Outbreak (settings described below) > Household Contact > Close Contact > Travel > Community > No information.\n",
    "Descriptions:\n",
    "\n",
    "-Household contact: Case who acquired infection from a household contact with a confirmed or probable COVID-19 case (e.g. family member, roommate).\n",
    "Close contact with a case: Case who acquired infection from a close contact with a confirmed or probable COVID-19 case (e.g. co-worker).\n",
    "-Outbreaks: Cases linked to known confirmed COVID-19 outbreaks. These could include the index case who may have acquired the infection elsewhere. Outbreaks settings include:\n",
    "    Outbreaks, Congregate Settings: confirmed outbreaks in Toronto in shelters, correctional facilities, group homes, or other congregate settings such as hostels or rooming houses.\n",
    "Outbreaks, Healthcare Institutions: confirmed outbreaks in Toronto in long-term care homes, retirement homes, hospitals, chronic care hospitals, or other institutional settings.\n",
    "    Outbreaks, Other Settings: confirmed outbreaks in Toronto in workplaces, schools, day cares, or outbreaks outside of Toronto. We do not validate outbreaks that occur in other health units, as such these cases may not be linked to confirmed outbreaks.\n",
    "-Travel: Case that travelled outside of Ontario in the 14 days prior to their symptom onset or test date, whichever is the earliest.\n",
    "-Community: Cases who did not travel outside of Ontario, did not identify being a close contact with a COVID-19 case, and were not part of a known confirmed COVID-19 outbreak.\n",
    "-No information: Cases with no information on the source of infection\n",
    "\n",
    "* **Classification**\n",
    "\n",
    "The application of the provincial case definition to categorize the cases as confirmed or probable, according to standard criteria. Please refer to the Ontario Ministry of Health website for Ontario's current provincial case definitions.\n",
    "\n",
    "* **Episode Date**\n",
    "\n",
    "The episode date is a derived variable that best estimates when the disease was acquired, and refers to the earliest available date from: symptom onset (the first day that COVID-19 symptoms occurred), laboratory specimen collection date, or reported date.\n",
    "\n",
    "* **Reported Date**\n",
    "\n",
    "The date on which the case was reported to Toronto Public Health.\n",
    "\n",
    "* **Client Gender**\n",
    "\n",
    "Self-reported gender. Gender is a system that operates in a social context and generally classifies people based on their assigned biological sex.\n",
    "\n",
    "* **Outcome**\n",
    "\n",
    "-Fatal: Any case that has died and has been marked as Outcome equals 'Fatal' and Type of Death does not equal 'Disease of Public Health Significance was unrelated to cause of death' in the provincial reporting system (CCM).\n",
    "\n",
    "-Resolved: Cases who have:\n",
    "\n",
    "A case outcome description in CCM of 'Recovered' OR\n",
    "Case outcome description is equal to 'Fatal' AND Type of Death is equal to 'Disease of Public Health Significance was unrelated to cause of death' OR\n",
    "Today's date is more than 14 days from episode date AND the case is not currently hospitalized/intubated/in ICU AND Case outcome description is not equal to 'Fatal' where Type of Death is not equal to 'Disease of Public Health Significance was unrelated to cause of death'.\n",
    "\n",
    "-Active: All other cases\n",
    "\n",
    "* **Currently Hospitalized**\n",
    "\n",
    "Cases that are currently admitted to hospital (i.e., no discharge date reported).\n",
    "\n",
    "* **Currently in ICU**\n",
    "\n",
    "Cases that are currently admitted to the intensive care unit (ICU) (i.e. no discharge date reported).\n",
    "\n",
    "* **Currently Intubated**\n",
    "\n",
    "Cases that were intubated related to their COVID-19 infection (includes cases that are currently intubated and those that have been discharged or deceased).\n",
    "\n",
    "**Ever Hospitalized**\n",
    "\n",
    "Cases that were hospitalized related to their COVID-19 infection (includes cases that are currently hospitalized and those that have been discharged or are deceased).\n",
    "\n",
    "**Ever in ICU**\n",
    "\n",
    "Cases that were admitted to the intensive care unit (ICU) related to their COVID-19 infection (includes cases that are currently in ICU and those that have been discharged or are deceased).\n",
    "\n",
    "**Ever Intubated**\n",
    "\n",
    "Cases that were intubated related to their COVID-19 infection (includes cases that are currently intubated and those that have been discharged or deceased)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19dd3f4-453a-4bd2-b1cc-702a338d3a8d",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f97c81-738e-4482-9fbc-b88715408a4a",
   "metadata": {},
   "source": [
    "Given the goals set for this project, the data available will be processed in different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481dc6af-c5e8-4a82-8170-052986b046b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as date\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import category_encoders as ce\n",
    "from sklearn import metrics as mt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_recall_curve, plot_precision_recall_curve, average_precision_score, auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction import text\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840f861-bb3a-42d0-afd9-2621e2510cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and store copies for ML and NLP, indexing by Episode Date\n",
    "df = pd.read_csv(r\"C:\\Users\\migue\\OneDrive\\Desktop\\Bootcamp Projects\\COVID19 in Toronto - ML and NLP\\COVID19 cases.csv\", index_col='Assigned_ID', infer_datetime_format= True)\n",
    "\n",
    "# copy for NLP\n",
    "df_nlp = df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e816b70-9052-4532-9b54-889b4c510b78",
   "metadata": {},
   "source": [
    "Before moving along, I want to get an idea of the generalities of the data set to assess what transformations should be advisable to make. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2751480f-1933-4bb2-ac91-e29fe97b8364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbed5a63-2ded-49da-b05f-5fec11c73fcb",
   "metadata": {},
   "source": [
    "It is a good thing not to have to deal with null values, and from what can be seen, theres time data that is not taken as such. Also, most of the categorical data is not taken as such either.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c091f13e-5837-4504-a76d-43bc44b7f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through object-based types to convert them into categorical types\n",
    "for col in df.select_dtypes(['object']):\n",
    "    df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c67c44b-324a-42c9-9642-49e9ed1e143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64089b6-7d10-4219-b540-2d50efde13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Reported and Episode Date a datetime type\n",
    "df['Episode Date'] = df['Episode Date'].astype('datetime64')\n",
    "df['Reported Date'] = df['Reported Date'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f028327-a4e1-45d0-9de2-90f32398a9bf",
   "metadata": {},
   "source": [
    "One thing of note, at this point, is that the categorical dimensiones have different cardinalities. Some are binary in nature, but others, like age or gender have different labels. Other variables, such as the source of infection, are also multilable. Let's get a look at the different labels per categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649565d-c0f7-421e-8e73-e4e6b923775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all categorical varaibles, check out the cardinality\n",
    "for col in df.select_dtypes(['category']):\n",
    "    print(df[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6156c3-86f2-4338-b95f-a958b905653d",
   "metadata": {},
   "source": [
    "#### Encoding the Categorical Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba626d8-6f10-4c06-b31e-a84548fe543f",
   "metadata": {},
   "source": [
    "With the above information, I am going to first map the low cardinality variables in a binary manner. For the rest, I will one-hot encode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722de7c4-17f4-4e31-9781-ff74135d1a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode labels (low-cardinality variables)\n",
    "# these are to be hot encoded\n",
    "df.Classification = df.Classification.map({'CONFIRMED': 0 , 'PROBABLE': 1})\n",
    "df['Currently Hospitalized'] = df['Currently Hospitalized'].map({'No': 0, 'Yes': 1})\n",
    "df['Currently Intubated'] = df['Currently Intubated'].map({'No': 0, 'Yes': 1})\n",
    "df['Currently in ICU'] = df['Currently in ICU'].map({'No': 0, 'Yes': 1})\n",
    "df['Outbreak Associated'] = df['Outbreak Associated'].map({'Sporadic': 0, 'Outbreak Associated': 1})\n",
    "df['Ever Hospitalized'] = df['Ever Hospitalized'].map({'No': 0, 'Yes': 1})\n",
    "df['Ever Intubated'] = df['Ever Intubated'].map({'No': 0, 'Yes': 1})\n",
    "df['Ever in ICU'] = df['Ever in ICU'].map({'No': 0, 'Yes': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bdb1e-55e7-4f8d-8bbe-ec1b671e0e86",
   "metadata": {},
   "source": [
    "For the following variables, I have encoded them using [Category Encoders](https://contrib.scikit-learn.org/category_encoders/). \n",
    "\n",
    "Given the taxonomy for 'Outcome' I consider an ordinal encoding to be fitting (labels are given in relation to the size of each sub sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8698f1ce-f223-4382-ae50-e24bac1bca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode rest of variables\n",
    "encoder1 = ce.OneHotEncoder(cols=['Client Gender'], return_df=True)\n",
    "df = encoder1.fit_transform(df, df['Client Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac186b4-9360-4300-b23f-1c801d90a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder2 = ce.OneHotEncoder(cols=['Source of Infection'], return_df=True)\n",
    "df = encoder2.fit_transform(df, df['Source of Infection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81ee0f-f7a2-4e4b-845c-c98c2e5b9cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder3 = ce.OrdinalEncoder(cols=['Outcome'], return_df=True)\n",
    "df=encoder3.fit_transform(df, df['Outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46b1c8e-4eac-4382-ad58-9a31ed46bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder4= ce.OneHotEncoder(cols=['Age Group'], return_df=True)\n",
    "df = encoder4.fit_transform(df, df['Age Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce11dc3-67f7-4c0b-8017-eed201760d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_low_card= ce.BinaryEncoder(cols=['Classification','Currently Hospitalized', 'Currently Intubated','Currently in ICU', 'Outbreak Associated',\n",
    "                                        #'Ever Hospitalized', 'Ever Intubated','Ever in ICU'])\n",
    "#df = encoder_low_card.fit_transform(df, df[['Classification','Currently Hospitalized', 'Currently Intubated','Currently in ICU', 'Outbreak Associated',\n",
    "                                        #'Ever Hospitalized', 'Ever Intubated','Ever in ICU']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc34c55-c40c-4ae8-8fb6-a3b8573a9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick check to verify all encoded columns are correctly encoded\n",
    "for c in df:\n",
    "    print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c0b15-9957-499d-8759-aeed90a8ea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns that were just encoded\n",
    "df= df.rename(columns={'Age Group_1':'19 and younger', 'Age Group_2':'20 to 29 Years', 'Age Group_3': '30 to 39 Years', 'Age Group_4': '40 to 49 Years',\n",
    "                       'Age Group_5': '50 to 59 Years', 'Age Group_6': '60 to 69 Years', 'Age Group_7': '70 to 79 Years', 'Age Group_8': '80 to 89 Years',\n",
    "                       'Age Group_9': '90 and older', 'Age Group_10': 'Age Unknown', \n",
    "                       'Client Gender_1': 'Female', 'Client Gender_2': 'Male', 'Client Gender_3': 'Gender Unknown',\n",
    "                      'Client Gender_4': 'Non-binary', 'Client Gender_5': 'Other','Client Gender_6':'Trans Man',\n",
    "                      'Client Gender_7':'Trans Woman', 'Client Gender_8': 'Transgender', 'Client Gender_9': 'Gender Not Listed: Please Specify',\n",
    "                      'Source of Infection_1':'Source of Infection: No Information','Source of Infection_2': 'Source of Infection: Community', 'Source of Infection_3': 'Source of Infection: Household Contact',\n",
    "                      'Source of Infection_4': 'Source of Infection: Outbreaks, Healthcare Institutions', 'Source of Infection_5': 'Source of Infection: Close Contact',\n",
    "                      'Source of Infection_6': 'Source of Infection: Outbreaks, Other Settings', 'Source of Infection_7': 'Source of Infection: Outbreaks, Congregate Settings',\n",
    "                      'Source of Infection_8': 'Source of Infection: Travel', 'Source of Infection_9': 'Source of Infection: Pending'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbf0711-f559-4fae-b600-c8bf3bf29997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# peek at the final look of the data frame, once everything's been encoded\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a82adf7-9603-4dcc-a0fa-47a96e5f4213",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ecb4c6-1341-4503-b32f-01d761e2b358",
   "metadata": {},
   "source": [
    "My targets of choice for my classifications analyses will be 'Outcome' and 'Outbreak Associated.'\n",
    "\n",
    "Before moving forward, let's first take a look at how are the observations distributed in each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cababa30-49ba-48b7-b374-62f635112e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "100* (df['Classification'].value_counts()) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad58ad0-e39c-49f9-b233-5fe948786855",
   "metadata": {},
   "outputs": [],
   "source": [
    "100*(df['Outcome'].value_counts()) / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e07af3-3e86-461b-924c-fae3024dd6cd",
   "metadata": {},
   "source": [
    "#### Random Forest Classification (for Outbreak Associated variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf65366-6968-4d29-9d0b-80daedfca7f5",
   "metadata": {},
   "source": [
    "For this model, I am going to use a random forest classifier to tell apart from sporadic infection events from those outbreak-related. Hospitalizations are not a variable to be included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4815fae-1dab-4fa1-be99-8fff9fec3201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input and target variables\n",
    "# while I think it holds some value, I am going to leave geogrpahy and chronology out of the question\n",
    "\n",
    "X = df.drop(columns = ['Reported Date', 'Episode Date', 'FSA', 'Neighbourhood Name', 'Outbreak Associated', 'Age Unknown', 'Gender Unknown', 'Gender Not Listed: Please Specify', 'Currently Hospitalized', 'Currently Intubated', 'Currently in ICU', 'Ever Hospitalized', 'Ever Intubated', 'Ever in ICU'], axis=1)\n",
    "y = df['Outbreak Associated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8128420f-a8a5-4bcd-9370-c31007a913cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.25, random_state = 20)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9398658-4789-46df-8623-f78aa3bb67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model that will only be able to tell the majority class, never the minority one\n",
    "y_train_baseline = pd.Series(np.zeros(len(y_train)))\n",
    "y_test_baseline = pd.Series(np.zeros(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341749c1-ba14-48ab-b3d2-9909a45b9ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest model\n",
    "rfc= RandomForestClassifier(n_estimators=1000, random_state=39, max_depth=2, n_jobs=4)\n",
    "model_fit = rfc.fit(X_train, y_train)\n",
    "y_train_rfc= rfc.predict(X_train)\n",
    "y_test_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa805bc9-f288-4d86-8353-64e11bcaaf5d",
   "metadata": {},
   "source": [
    "The baseline model, as expected, does not detect a minority class at all and its average recall being 50% might indicate this is a random model. Let's keep that in mind when assessing the classification report for actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b915e13-06bc-4481-9078-1b29ced6a28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_baseline, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95823105-87a4-48b1-acc1-3e35963259da",
   "metadata": {},
   "source": [
    "The random forest classifier does a good job in getting the majority class (label 0), but struggles when it comes to get the actual true positives for the minority class(recall value is 9%). Across both classes, if we take both recall scores, the balanced accuracy (the average recall for each label), is of 54% (the macro average in the report). Accuracy and its balanced counterpart show mismatch that points at an imbalanced distribution of the data. Most of the cases are then labeled under 'sporadic.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00484ce0-92d1-4984-9cc7-1faee3420955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_rfc, labels = [0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf16025-40c0-4d84-a871-502481932f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(rfc, X_test, y_test, display_labels=[0,1], cmap='Reds')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded03910-fc43-482c-85f2-399a8ab47611",
   "metadata": {},
   "source": [
    "The precision-recall curve, a computation of the precision (the ratio of actual trues divided by the sum of all values identified as true, actual or not) against the recall (the ratio of actual true values divided by the sum of actual true values, regardless of whether they are correctly identified or not) for a classifier given different thresholds. A shape like the one shown below, gives the impression of the classifier being 'perfect', as it has been able to score perfect precision and recall at every threshold. This is far from perfect. With imbalaced datasets, the precision recall curve captures well what's going on with the classification model, as [Soledad Galli demonstrates here.](https://github.com/solegalli/machine-learning-imbalanced-data/blob/master/Section-03-Metrics/03-08-Optional-Comparison-ROC-PRC.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d39c8b-0e98-4b53-a9b3-e95fccc06b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(rfc, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55728fc2-68c5-4ad2-86bd-d86282e500fc",
   "metadata": {},
   "source": [
    "#### Random Forest Classification (for Outcome variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab48cb-baf4-406e-baeb-5df2d44486ef",
   "metadata": {},
   "source": [
    "With the results for a binary class in mind, let's see what happens with a multi-label variable, the outcome for each reported case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa23ae7-3c67-45ec-a298-3899c10bae81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the input and target variables\n",
    "# while I think it holds some value, I am going to leave geogrpahy and chronology out of the question\n",
    "# Majority and minority classes are defined by the order in which Outcome was encoded\n",
    "\n",
    "X = df.drop(columns = ['Reported Date', 'Episode Date', 'FSA', 'Neighbourhood Name', 'Outcome', 'Age Unknown', 'Gender Unknown', 'Gender Not Listed: Please Specify', 'Currently Hospitalized', 'Currently Intubated', 'Currently in ICU', 'Ever Hospitalized', 'Ever Intubated', 'Ever in ICU'], axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a84f2f-141e-459c-b90f-5a29a4014b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.25, random_state = 20)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5406800-dccb-47a8-b8d4-f20432016572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a baseline model that will only be able to tell the majority class, never the minority one\n",
    "y_train_baseline = pd.Series(np.zeros(len(y_train)))\n",
    "y_test_baseline = pd.Series(np.zeros(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25f9e5-9677-431d-b5b0-552a9164bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest model\n",
    "rfc= RandomForestClassifier(n_estimators=1000, random_state=39, max_depth=2, n_jobs=4)\n",
    "model_fit = rfc.fit(X_train, y_train)\n",
    "y_train_rfc= rfc.predict(X_train)\n",
    "y_test_rfc = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2c41a-e3ca-4dfb-9434-c13b71947422",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_baseline, labels = [1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac214d7d-7ce4-4714-9add-75f9654b9ca2",
   "metadata": {},
   "source": [
    "The model only does a good job when telling which class is the majority one, but data seems so imbalanced that there is no score whatsoever for the minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae9fee-ae58-4ece-af06-2a8330bec860",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_rfc, labels = [1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016f081-f3b4-4ca9-960e-b5f739e49958",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_confusion_matrix(rfc, X_test, y_test, display_labels=[1,2,3], cmap='Reds')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9d79a-26d7-4eef-a878-752e0dffea0f",
   "metadata": {},
   "source": [
    "#### Dealing with Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69caaf2f",
   "metadata": {},
   "source": [
    "What are the ways we can make the classifier better in capturing the target variables? One way of going about it is to [undersample the majority class](https://imbalanced-learn.org/stable/references/under_sampling.html) until we reach an equal proportion of observations for any of the labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6fffb",
   "metadata": {},
   "source": [
    "##### Undersampling the Classification Model for the 'Outbreak Associated' Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791276be",
   "metadata": {},
   "source": [
    "###### Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate random undersampler\n",
    "rus = RandomUnderSampler(sampling_strategy=0.5, random_state=29, replacement='True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a061230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample X and Y variables for this model\n",
    "# initial run of rus triggered\n",
    "# 'Only the Series name can be used for the key in Series dtype mappings.' error\n",
    "# so I am passing X as an array and I am making Y a continuous one\n",
    "# check https://stackoverflow.com/questions/65311823/getting-error-keyerror-only-the-series-name-can-be-used-for-the-key-in-series\n",
    "X = df.drop(columns = ['Reported Date', 'Episode Date', 'FSA', 'Neighbourhood Name', 'Outbreak Associated', 'Age Unknown', 'Gender Unknown', 'Gender Not Listed: Please Specify', 'Currently Hospitalized', 'Currently Intubated', 'Currently in ICU', 'Ever Hospitalized', 'Ever Intubated', 'Ever in ICU'], axis=1)\n",
    "y = df['Outbreak Associated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fa45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled, y_undersampled = rus.fit_resample(X, y.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97391aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled.shape, y_undersampled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ce3350",
   "metadata": {},
   "source": [
    "Both the inputs and target are now resampled and aligned. Let's apply the machine learning algorithm again and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab45cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train / test split\n",
    "X_undersampled_train, X_undersampled_test, y_undersampled_train, y_undersampled_test = train_test_split(X_undersampled, y_undersampled, train_size = 0.25, random_state = 34)\n",
    "X_undersampled_test.shape, y_undersampled_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ba4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=2000, max_depth=4, n_jobs=2, random_state=45)\n",
    "model = rfc.fit(X_undersampled_train, y_undersampled_train)\n",
    "y_undersampled_train_pred = model.predict(X_undersampled_train)\n",
    "y_undersampled_test_pred = model.predict(X_undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30861ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_undersampled_test, y_undersampled_test_pred, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ed380",
   "metadata": {},
   "source": [
    "Scores just skyrocketed all across the board. Unlike the case for imbalanced data, in which I used the precision-recall plot, now I am going to call the ROC-AUC plot to see how well this randomly undersampled model is able to tell both classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea60970",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(rfc, X_undersampled_train, y_undersampled_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e39e36",
   "metadata": {},
   "source": [
    "All across thresholds, this models is going to be able to be fully precise and sensible (recall). This is almost too good. An undersampled model in this case is an overfitted one? Would other methods provide different results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75bd24-b71e-44d7-8a6e-1ca6d550bc55",
   "metadata": {},
   "source": [
    "Now that the minority class has been balanced, it makes sense to use the ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85afc47-dbab-4c56-930a-4c802f3c2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_undersampled_test, y_undersampled_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ead736",
   "metadata": {},
   "source": [
    "###### Random Undersampling with Tomek's Links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80111d8-51bb-41db-b181-f90d92f9aa4d",
   "metadata": {},
   "source": [
    "With Tomek's Links, the resampling is computed to remove all the boundary/noisy instances between labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl= TomekLinks(sampling_strategy='auto', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90484953",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled_tl, y_undersampled_tl = tl.fit_resample(X, y.ravel())\n",
    "X_undersampled_train, X_undersampled_test, y_undersampled_train, y_undersampled_test = train_test_split(X_undersampled, y_undersampled, train_size = 0.25, random_state = 20)\n",
    "X_undersampled_train.shape, y_undersampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad4ca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=2000, max_depth=4, n_jobs=2, random_state=37)\n",
    "model = rfc.fit(X_undersampled_train, y_undersampled_train)\n",
    "y_undersampled_pred_tl = rfc.predict(X_undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dc740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_undersampled_test, y_undersampled_pred_tl, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd00642-e87b-4e94-beb9-f9af3975be0f",
   "metadata": {},
   "source": [
    "The ROC-AUC score resulting from this type of undersampling is also in the realm of excellency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a0445",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_undersampled_test, y_undersampled_pred_tl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529e2b91",
   "metadata": {},
   "source": [
    "##### Undersampling the Classification Model for the 'Outcome' Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ab87b",
   "metadata": {},
   "source": [
    "For this variable, given that it contains three labels, I will forfeit the random undersampling method and use instead Tomek's Links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe352a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate Tomek Links undersampler\n",
    "tl= TomekLinks(sampling_strategy='auto', n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8854c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['Reported Date', 'Episode Date', 'FSA', 'Neighbourhood Name', 'Outcome', 'Age Unknown', 'Gender Unknown', 'Gender Not Listed: Please Specify', 'Currently Hospitalized', 'Currently Intubated', 'Currently in ICU', 'Ever Hospitalized', 'Ever Intubated', 'Ever in ICU'], axis=1)\n",
    "y = df['Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_undersampled_tl, y_undersampled_tl = tl.fit_resample(X, y.ravel())\n",
    "X_undersampled_train, X_undersampled_test, y_undersampled_train, y_undersampled_test = train_test_split(X_undersampled, y_undersampled, train_size = 0.25, random_state = 20)\n",
    "X_undersampled_train.shape, y_undersampled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f7bfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=2000, max_depth=4, n_jobs=2, random_state=37)\n",
    "model = rfc.fit(X_undersampled_train, y_undersampled_train)\n",
    "y_undersampled_pred_tl = rfc.predict(X_undersampled_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fd20d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_undersampled_test, y_undersampled_pred_tl, labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1dd3ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fa17fc8",
   "metadata": {},
   "source": [
    "### Classifying Cases Given Source Neighborhood Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15424de",
   "metadata": {},
   "source": [
    "Can cases, be them confirmed or probable, explained by the neighborhood, the postal code and how the infection took place? Using the [Naive Bayes approach](https://jakevdp.github.io/PythonDataScienceHandbook/05.05-naive-bayes.html), I am going to build a classifier able to distinguish between cases that are confirmed or probable by looking at the place they were reported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf67153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bring up the copy of the df\n",
    "df_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e866cf9",
   "metadata": {},
   "source": [
    "As seen above, I am going to use the copy I stored at the beginning of the project. The reason why I am proceeding this way is that I dont want to use encoded values for my inputs, and I just to encode my target. Let's first be reminded of the distribution of values and have that in mind should it becomes a factor. The majority class will be 'Confirmed', whereas the minority will be 'Probable.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['Classification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the variable\n",
    "df_nlp['Classification'] = df_nlp['Classification'].map({'CONFIRMED': '0', 'PROBABLE': '1'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a8368",
   "metadata": {},
   "source": [
    "There seems to be a 'NaN' value in the column for neighborhood name. Let's replace it with a generic placeholder that won't skew the text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b14620",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nlp['Neighbourhood Name'] = df_nlp['Neighbourhood Name'].replace(np.nan, 'Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0763d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define now the input and target variables\n",
    "# define train and test splits\n",
    "X = df_nlp['Neighbourhood Name']\n",
    "y = df_nlp['Classification']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1600, test_size = 0.30)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e550ee8a",
   "metadata": {},
   "source": [
    "Now that the target is encoded, I need to process my categorial, textual data. For that, I will turn the vectors of words that make each text string of the variables I have chosen as inputs into bags-of-words (a count of the occurrence of each word).\n",
    "To that end, I will use [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d11d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordbag = text.CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f4a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the training and test sets\n",
    "X_train = wordbag.fit_transform(X_train)\n",
    "X_test = wordbag.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ba97e",
   "metadata": {},
   "source": [
    "Let's build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc1942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "nbm = MultinomialNB()\n",
    "nbm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd2c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = nbm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3349d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e5490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
